{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2203                                           Antz (1998)\n",
      "3021                                    Toy Story 2 (1999)\n",
      "3653        Adventures of Rocky and Bullwinkle, The (2000)\n",
      "3912                      Emperor's New Groove, The (2000)\n",
      "4780                                 Monsters, Inc. (2001)\n",
      "9949     DuckTales: The Movie - Treasure of the Lost La...\n",
      "10773                                     Wild, The (2006)\n",
      "11604                               Shrek the Third (2007)\n",
      "12969                       Tale of Despereaux, The (2008)\n",
      "17431    Asterix and the Vikings (Astérix et les Viking...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "movies = pd.read_csv('movies.csv')\n",
    "\n",
    "# TF-IDF Vectorizer for genres\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movies['genres'] = movies['genres'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['genres'])\n",
    "\n",
    "# Dimensionality reduction using TruncatedSVD\n",
    "n_components = min(20, tfidf_matrix.shape[1])  # Use 20 or less depending on the number of features\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "tfidf_matrix_reduced = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Compute cosine similarity on the reduced matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix_reduced, tfidf_matrix_reduced)\n",
    "\n",
    "# Function to get recommendations\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = movies[movies['title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies['title'].iloc[movie_indices]\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations('Toy Story (1995)'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57                       Postman, The (Postino, Il) (1994)\n",
      "2766                                American Beauty (1999)\n",
      "11514    Inglorious Bastards (Quel maledetto treno blin...\n",
      "13915     Dimensions of Dialogue (Moznosti dialogu) (1982)\n",
      "16927                      Bill Cunningham New York (2011)\n",
      "19611             Death on the Staircase (Soupçons) (2004)\n",
      "26741          Louis C.K.: Live at The Comedy Store (2015)\n",
      "26779                Story of Film: An Odyssey, The (2011)\n",
      "32968                               The Blue Planet (2001)\n",
      "45593                              Band of Brothers (2001)\n",
      "Name: title, dtype: object\n",
      "RMSE: 0.7779\n",
      "MAE:  0.5868\n",
      "Collaborative Filtering RMSE: 0.7778524829807567\n",
      "Collaborative Filtering MAE: 0.5867883398114546\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Use SVD algorithm for collaborative filtering\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Function to get collaborative filtering recommendations\n",
    "def get_collaborative_recommendations(user_id, algo=algo, n=10):\n",
    "    user_ratings = ratings[ratings['userId'] == user_id]\n",
    "    movie_ids = user_ratings['movieId'].unique()\n",
    "    all_movie_ids = ratings['movieId'].unique()\n",
    "    movie_ids_to_predict = [mid for mid in all_movie_ids if mid not in movie_ids]\n",
    "    \n",
    "    predictions = [algo.predict(user_id, mid) for mid in movie_ids_to_predict]\n",
    "    predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "    top_n_predictions = predictions[:n]\n",
    "    \n",
    "    recommended_movie_ids = [pred.iid for pred in top_n_predictions]\n",
    "    return movies[movies['movieId'].isin(recommended_movie_ids)]['title']\n",
    "\n",
    "# Example usage\n",
    "print(get_collaborative_recommendations(1))\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = algo.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "print(f\"Collaborative Filtering RMSE: {rmse}\")\n",
    "print(f\"Collaborative Filtering MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antz (1998)', 'Toy Story 2 (1999)', 'Adventures of Rocky and Bullwinkle, The (2000)', \"Emperor's New Groove, The (2000)\", 'Monsters, Inc. (2001)', 'DuckTales: The Movie - Treasure of the Lost Lamp (1990)', 'Wild, The (2006)', 'Shrek the Third (2007)', 'Tale of Despereaux, The (2008)', 'Asterix and the Vikings (Astérix et les Vikings) (2006)']\n"
     ]
    }
   ],
   "source": [
    "def hybrid_recommendations(title, user_id, n=10):\n",
    "    content_recommendations = get_recommendations(title)\n",
    "    collaborative_recommendations = get_collaborative_recommendations(user_id)\n",
    "    \n",
    "    # Combine recommendations\n",
    "    combined_recommendations = list(content_recommendations) + list(collaborative_recommendations)\n",
    "    \n",
    "    # Remove duplicates while maintaining order\n",
    "    seen = set()\n",
    "    final_recommendations = []\n",
    "    for movie in combined_recommendations:\n",
    "        if movie not in seen:\n",
    "            final_recommendations.append(movie)\n",
    "            seen.add(movie)\n",
    "    \n",
    "    return final_recommendations[:n]\n",
    "\n",
    "# Example usage\n",
    "print(hybrid_recommendations('Toy Story (1995)', 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.375\n",
      "Recall: 0.375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Assuming you have ground truth data for user recommendations\n",
    "# ground_truth_recommendations = {user_id: [list of relevant movie_ids]}\n",
    "# predicted_recommendations = {user_id: [list of predicted movie_ids]}\n",
    "\n",
    "def evaluate_recommendations(ground_truth, predictions):\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "\n",
    "    for user_id in ground_truth:\n",
    "        true_positives = len(set(ground_truth[user_id]) & set(predictions[user_id]))\n",
    "        precision = true_positives / len(predictions[user_id]) if predictions[user_id] else 0\n",
    "        recall = true_positives / len(ground_truth[user_id]) if ground_truth[user_id] else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "\n",
    "    avg_precision = sum(all_precisions) / len(all_precisions)\n",
    "    avg_recall = sum(all_recalls) / len(all_recalls)\n",
    "\n",
    "    return avg_precision, avg_recall\n",
    "\n",
    "# Example usage\n",
    "ground_truth_recommendations = {\n",
    "    1: [10, 20, 30, 40],\n",
    "    2: [50, 60, 70, 80],\n",
    "}\n",
    "\n",
    "predicted_recommendations = {\n",
    "    1: [10, 25, 30, 45],\n",
    "    2: [55, 60, 75, 85],\n",
    "}\n",
    "\n",
    "precision, recall = evaluate_recommendations(ground_truth_recommendations, predicted_recommendations)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
